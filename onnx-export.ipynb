{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35fb0c29-1d76-43ff-b29c-4e764e067441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-01-20 21:44:00 transformer_bpe_models:59] Could not import NeMo NLP collection which is required for speech translation model.\n"
     ]
    }
   ],
   "source": [
    "from nemo.collections.tts.models import HifiGanModel, Tacotron2Model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3ea2bc-013c-4c3a-80ef-b29b699269c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-01-20 21:44:02 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.asr.data.audio_to_text.AudioToCharDataset\n",
      "      manifest_filepath: trim_voice5/common_train.json\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      trim: false\n",
      "      int_values: false\n",
      "      normalize: false\n",
      "      sample_rate: 22050\n",
      "      parser: base\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: true\n",
      "      batch_size: 32\n",
      "      num_workers: 5\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:02 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.asr.data.audio_to_text.AudioToCharDataset\n",
      "      manifest_filepath: trim_voice5/common_test.json\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      int_values: false\n",
      "      normalize: false\n",
      "      sample_rate: 22050\n",
      "      trim: false\n",
      "      parser: base\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 32\n",
      "      num_workers: 5\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-01-20 21:44:02 features:289] PADDING: 16\n",
      "[NeMo I 2024-01-20 21:44:04 save_restore_connector:249] Model Tacotron2Model was successfully restored from /root/.cache/huggingface/hub/models--lunarlist--tts-thai-last-step/snapshots/de2b736ac7f8adf7eeb6afd04f438bd4ecf76a37/tts-thai-last-step.nemo.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tacotron2Model(\n",
       "  (audio_to_melspec_precessor): FilterbankFeatures()\n",
       "  (text_embedding): Embedding(69, 512)\n",
       "  (encoder): Encoder(\n",
       "    (convolutions): ModuleList(\n",
       "      (0-2): 3 x Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (lstm): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (prenet): Prenet(\n",
       "      (layers): ModuleList(\n",
       "        (0): LinearNorm(\n",
       "          (linear_layer): Linear(in_features=80, out_features=256, bias=False)\n",
       "        )\n",
       "        (1): LinearNorm(\n",
       "          (linear_layer): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (attention_rnn): LSTMCell(768, 1024)\n",
       "    (attention_layer): Attention(\n",
       "      (query_layer): LinearNorm(\n",
       "        (linear_layer): Linear(in_features=1024, out_features=128, bias=False)\n",
       "      )\n",
       "      (memory_layer): LinearNorm(\n",
       "        (linear_layer): Linear(in_features=512, out_features=128, bias=False)\n",
       "      )\n",
       "      (v): LinearNorm(\n",
       "        (linear_layer): Linear(in_features=128, out_features=1, bias=False)\n",
       "      )\n",
       "      (location_layer): LocationLayer(\n",
       "        (location_conv): ConvNorm(\n",
       "          (conv): Conv1d(2, 32, kernel_size=(31,), stride=(1,), padding=(15,), bias=False)\n",
       "        )\n",
       "        (location_dense): LinearNorm(\n",
       "          (linear_layer): Linear(in_features=32, out_features=128, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder_rnn): LSTMCell(1536, 1024, bias=1)\n",
       "    (linear_projection): LinearNorm(\n",
       "      (linear_layer): Linear(in_features=1536, out_features=80, bias=True)\n",
       "    )\n",
       "    (gate_layer): LinearNorm(\n",
       "      (linear_layer): Linear(in_features=1536, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (postnet): Postnet(\n",
       "    (convolutions): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1-3): 3 x Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 80, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (loss): Tacotron2Loss()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_generator = Tacotron2Model.from_pretrained(\"lunarlist/tts-thai-last-step\").to(\"cpu\")\n",
    "spec_generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "041750a9-e7cd-4eb6-b615-293e7bcfca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dim=512\n",
    "seq = torch.randint(low=0, high=69, size=(1, max_dim), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc69d1b-addb-4ba8-8a00-f79f2b23287d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0019, -0.0150,  0.0101,  ..., -0.0445, -0.0157, -0.0259],\n",
       "         [ 0.0232,  0.0053,  0.0100,  ..., -0.0187, -0.0009,  0.0540],\n",
       "         [-0.0078,  0.0010, -0.0127,  ...,  0.0167, -0.0198,  0.0002],\n",
       "         ...,\n",
       "         [-0.0038,  0.0170,  0.0075,  ...,  0.0188,  0.0198,  0.0014],\n",
       "         [ 0.0008,  0.0236,  0.0266,  ...,  0.0762, -0.0061, -0.0028],\n",
       "         [ 0.0209, -0.0323,  0.0411,  ..., -0.0438,  0.0121,  0.0308]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_generator.text_embedding(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "868452bc-bd27-4fa3-a8c3-7eda66f19323",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed2=torch.Tensor([[66]+[2]+[67]]).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3be888a-c455-41f7-8383-1598973a7941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-01-20 21:44:05 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input seq\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:05 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input seq_len\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:05 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input memory\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:05 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input processed_memory\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:05 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input lens\n",
      "      warnings.warn(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of prim::PackPadded type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of prim::PackPadded type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[NeMo W 2024-01-20 21:44:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/symbolic_opset9.py:4476: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "      warnings.warn(\n",
      "    \n",
      "[W shape_type_inference.cpp:1920] Warning: The shape inference of prim::PadPacked type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 3 WARNING 0 ERROR ========================\n",
      "3 WARNING were not printed due to the log level.\n",
      "\n",
      "[NeMo I 2024-01-20 21:44:06 exportable:130] Successfully exported EncoderIter to tacotron2encoder-th.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-01-20 21:44:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input decoder_input\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input attention_hidden\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input attention_cell\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input decoder_hidden\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input decoder_cell\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input attention_weights\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input attention_weights_cum\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input attention_context\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input decoder_output\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input gate_prediction\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input out_attention_hidden\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input out_attention_cell\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input out_decoder_hidden\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input out_decoder_cell\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input out_attention_weights\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input out_attention_weights_cum\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:06 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input out_attention_context\n",
      "      warnings.warn(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[NeMo I 2024-01-20 21:44:07 exportable:130] Successfully exported DecoderIter to tacotron2decoder-th.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-01-20 21:44:07 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input mel_spec\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-01-20 21:44:07 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input output\n",
      "      warnings.warn(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "[NeMo I 2024-01-20 21:44:07 exportable:130] Successfully exported PostnetIter to tacotron2postnet-th.onnx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['tacotron2encoder-th.onnx',\n",
       "  'tacotron2decoder-th.onnx',\n",
       "  'tacotron2postnet-th.onnx'],\n",
       " ['nemo.collections.tts.models.tacotron2.EncoderIter exported to ExportFormat.ONNX',\n",
       "  'nemo.collections.tts.models.tacotron2.DecoderIter exported to ExportFormat.ONNX',\n",
       "  'nemo.collections.tts.models.tacotron2.PostnetIter exported to ExportFormat.ONNX'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_generator.export(\"th.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dc28d3-7542-4e93-88b6-865f3d801e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "v=spec_generator.generate_spectrogram(tokens=parsed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b3316-9093-4030-a081-818295cf747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc3e538e-840c-48e0-8822-7cfd61627165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ก', 'ข', 'ค', 'ฆ', 'ง', 'จ', 'ฉ', 'ช', 'ซ', 'ฌ', 'ญ', 'ฎ', 'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท', 'ธ', 'น', 'บ', 'ป', 'ผ', 'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ฤ', 'ล', 'ว', 'ศ', 'ษ', 'ส', 'ห', 'ฬ', 'อ', 'ฮ', 'ะ', 'ั', 'า', 'ำ', 'ิ', 'ี', 'ึ', 'ื', 'ุ', 'ู', 'เ', 'แ', 'โ', 'ใ', 'ไ', 'ๅ', '็', '่', '้', '๊', '๋', '์', ' ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_generator.hparams[\"cfg\"]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7936856-3d25-4878-8440-8ec28708cc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_generator.decoder.n_mel_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd3b96a-741f-4283-ac4e-7bee960cd1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_generator.decoder.n_frames_per_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f97bf4a-1c3d-4677-816e-c8bcf163ba6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_generator.decoder.attention_rnn_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce7958e6-2313-4c74-acf1-6d9dd4486119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_generator.decoder.decoder_rnn_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "096222e2-a76b-410a-ab12-a7cd171a8570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_generator.decoder.encoder_embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ead87bf-04e5-4352-b59a-7b0f1f9dbba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_generator.decoder.n_mel_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f15acd-8d14-47d4-9a04-5f439d084fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
